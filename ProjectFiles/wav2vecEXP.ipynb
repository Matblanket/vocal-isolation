{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-20T20:57:14.972355Z",
     "iopub.status.busy": "2025-04-20T20:57:14.971785Z",
     "iopub.status.idle": "2025-04-20T20:58:09.179492Z",
     "shell.execute_reply": "2025-04-20T20:58:09.178821Z",
     "shell.execute_reply.started": "2025-04-20T20:57:14.972334Z"
    },
    "id": "2EJf6tVwXiOl",
    "outputId": "e2b3419e-a4ac-4719-8c1a-f0e741649519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/cuda-repo-ubuntu2204-12-0-local  InRelease [1575 B]\n",
      "Get:1 file:/var/cuda-repo-ubuntu2204-12-0-local  InRelease [1575 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]m\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:4 https://deb.nodesource.com/node_20.x nodistro InRelease [12.1 kB]        \u001b[0m\u001b[33m\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4000 kB]\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \u001b[0m\n",
      "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1243 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2788 kB][33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]       \u001b[0m\n",
      "Get:11 https://deb.nodesource.com/node_20.x nodistro/main amd64 Packages [10.8 kB]m\u001b[33m\u001b[33m\n",
      "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1604 kB]\n",
      "Get:13 https://packagecloud.io/github/git-lfs/ubuntu jammy InRelease [29.2 kB] \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1542 kB]m\u001b[33m\n",
      "Get:15 https://packagecloud.io/github/git-lfs/ubuntu jammy/main amd64 Packages [2213 B]\n",
      "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]m\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4246 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3140 kB]\n",
      "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [82.7 kB]33m\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Fetched 19.3 MB in 1s (14.4 MB/s)[33m                        \u001b[0m              \u001b[0m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "258 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libaria2-0 libc-ares2 libssh2-1\n",
      "The following NEW packages will be installed:\n",
      "  aria2 libaria2-0 libc-ares2 libssh2-1\n",
      "0 upgraded, 4 newly installed, 0 to remove and 258 not upgraded.\n",
      "Need to get 1622 kB of archives.\n",
      "After this operation, 5817 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libssh2-1 amd64 1.10.0-3 [109 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1086 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
      "Fetched 1622 kB in 0s (15.1 MB/s)0m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libc-ares2:amd64.\n",
      "(Reading database ... 89952 files and directories currently installed.)\n",
      "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libssh2-1:amd64.\n",
      "Preparing to unpack .../libssh2-1_1.10.0-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libssh2-1:amd64 (1.10.0-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libaria2-0:amd64.\n",
      "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package aria2.\n",
      "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking aria2 (1.36.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libssh2-1:amd64 (1.10.0-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up aria2 (1.36.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.5) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J\n",
      "04/20 20:57:20 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
      "\u001b[35m[\u001b[0m#77d7e2 16GiB/16GiB\u001b[36m(98%)\u001b[0m CN:16 DL:\u001b[32m469MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0mmm\n",
      "04/20 20:58:09 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /wham_noise.zip\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "77d7e2|\u001b[1;32mOK\u001b[0m  |   490MiB/s|/wham_noise.zip\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "Archive:  ../wham_noise.zip\n",
      "caution: filename not matched:  -q\n"
     ]
    }
   ],
   "source": [
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:51:41.112593Z",
     "iopub.status.busy": "2025-04-22T21:51:41.111981Z",
     "iopub.status.idle": "2025-04-22T21:51:44.940760Z",
     "shell.execute_reply": "2025-04-22T21:51:44.939746Z",
     "shell.execute_reply.started": "2025-04-22T21:51:41.112551Z"
    },
    "id": "Vhz5QSCYfN5R",
    "outputId": "a76e3451-8733-4fe0-a5b6-eb19dc3f306b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mir_eval\n",
      "  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.11.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mir_eval) (5.1.1)\n",
      "Downloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mir_eval\n",
      "Successfully installed mir_eval-0.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mir_eval git+https://github.com/faroit/stempeg git+https://github.com/sigsep/sigsep-mus-db hyperpyyaml speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-24T19:44:34.934337Z",
     "iopub.status.busy": "2025-04-24T19:44:34.934102Z",
     "iopub.status.idle": "2025-04-24T19:44:34.945186Z",
     "shell.execute_reply": "2025-04-24T19:44:34.944566Z",
     "shell.execute_reply.started": "2025-04-24T19:44:34.934318Z"
    },
    "id": "Ns_Lkvv_kgwE",
    "outputId": "a63b2792-dc47-46e1-dc9d-3a3ea801b0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Transformer.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file Transformer.yaml\n",
    "# ################################\n",
    "# Model: SepFormer for source separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : Libri2mix\n",
    "# ################################\n",
    "#\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "#\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "\n",
    "# e.g. '/yourpath/Libri2Mix/train-clean-360/'\n",
    "# the data folder is needed even if dynamic mixing is applied\n",
    "data_folder: /yourpath/Libri2Mix/train-clean-360/\n",
    "\n",
    "# this is the base folder for dynamic mixing\n",
    "base_folder_dm: /yourpath/LibriSpeech/train-clean-360/\n",
    "\n",
    "experiment_name: moeformer-libri2mix\n",
    "output_folder: !ref results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <save_folder>/libri2mix_train-360.csv\n",
    "valid_data: !ref <save_folder>/libri2mix_dev.csv\n",
    "test_data: !ref <save_folder>/libri2mix_test.csv\n",
    "skip_prep: False\n",
    "\n",
    "ckpt_interval_minutes: 60\n",
    "\n",
    "# Experiment params\n",
    "num_spks: 2\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 16000\n",
    "\n",
    "wav2vec2_hub: facebook/wav2vec2-base-960h\n",
    "wav2vec2_folder: !ref <save_folder>/wav2vec2_checkpoint\n",
    "freeze_wav2vec: True\n",
    "freeze_feature_extractor: True\n",
    "wav2vec_output_dim: 1024\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 200\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "lr_wav2vec: 0.0001\n",
    "\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "# if True, the training sequences are cut to a specified length\n",
    "limit_training_signal_len: True\n",
    "# this is the length of sequences if we choose to limit\n",
    "# the signal length of training sequences\n",
    "training_signal_len: 16000\n",
    "\n",
    "# Set it to True to dynamically create mixtures at training time\n",
    "dynamic_mixing: False\n",
    "use_wham_noise: False\n",
    "\n",
    "# Speed perturbation\n",
    "speed_changes: [95, 100, 105]  # List of speed changes for time-stretching\n",
    "\n",
    "speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n",
    "    orig_freq: !ref <sample_rate>\n",
    "    speeds: !ref <speed_changes>\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "d_ffn: 1024\n",
    "dnn_neurons: 1999\n",
    "dropout: 0.15\n",
    "\n",
    "# Dataloader options\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 8\n",
    "\n",
    "wav2vec2: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2\n",
    "    source: !ref <wav2vec2_hub>\n",
    "    output_norm: True\n",
    "    freeze: !ref <freeze_wav2vec>\n",
    "    freeze_feature_extractor: !ref <freeze_feature_extractor>\n",
    "    save_path: !ref <wav2vec2_folder>\n",
    "\n",
    "# # Specifying othe network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "\n",
    "    # linear2: !name:speechbrain.nnet.linear.Linear\n",
    "    #     n_neurons: !ref <dnn_neurons>\n",
    "    #     bias: True\n",
    "    # bn2: !name:speechbrain.nnet.normalization.BatchNorm1d\n",
    "    # activation2: !new:torch.nn.LeakyReLU\n",
    "    # drop2: !new:torch.nn.Dropout\n",
    "    #     p: !ref <dropout>\n",
    "    # linear3: !name:speechbrain.nnet.linear.Linear\n",
    "    #     n_neurons: !ref <dnn_neurons>\n",
    "    #     bias: True\n",
    "    # bn3: !name:speechbrain.nnet.normalization.BatchNorm1d\n",
    "    # activation3: !new:torch.nn.LeakyReLU\n",
    "\n",
    "\n",
    "SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
    "    num_spks: !ref <num_spks>\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    # in_channels: !ref <N_encoder_out>\n",
    "    out_channels: !ref <out_channels>\n",
    "    num_layers: 2\n",
    "    K: 250\n",
    "    intra_model: !ref <SBtfintra>\n",
    "    inter_model: !ref <SBtfinter>\n",
    "    norm: ln\n",
    "    linear_layer_after_inter_intra: False\n",
    "    skip_around_intra: True\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "Linear: !new:speechbrain.nnet.containers.Sequential\n",
    "    input_shape: [null, null, 37632]\n",
    "    linear1: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: 16000\n",
    "        bias: True\n",
    "    activation: !new:torch.nn.LeakyReLU\n",
    "    drop: !new:torch.nn.Dropout\n",
    "        p: !ref <dropout>\n",
    "\n",
    "\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "# wav2vec_opt_class: !name:torch.optim.Adam\n",
    "#     lr: !ref <lr_wav2vec>\n",
    "\n",
    "    \n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 5\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    wav2vec2: !ref <wav2vec2>\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "    Linear: !ref <Linear>\n",
    "\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        counter: !ref <epoch_counter>\n",
    "        wav2vec2: !ref <wav2vec2>\n",
    "        Linear: !ref <Linear>\n",
    "        # lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "# If you do not want to use the pretrained separator you can simply delete pretrained_separator field.\n",
    "# pretrained_separator: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
    "#     collect_in: !ref <save_folder>\n",
    "#     loadables:\n",
    "#         encoder: !ref <Encoder>\n",
    "#         decoder: !ref <Decoder>\n",
    "#         masknet: !ref <MaskNet>\n",
    "#     paths:\n",
    "#         encoder: speechbrain/sepformer-wsj02mix/encoder.ckpt\n",
    "#         decoder: speechbrain/sepformer-wsj02mix/decoder.ckpt\n",
    "#         masknet: speechbrain/sepformer-wsj02mix/masknet.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-24T19:44:35.987794Z",
     "iopub.status.busy": "2025-04-24T19:44:35.987552Z",
     "iopub.status.idle": "2025-04-24T19:44:36.000152Z",
     "shell.execute_reply": "2025-04-24T19:44:35.999731Z",
     "shell.execute_reply.started": "2025-04-24T19:44:35.987775Z"
    },
    "id": "OWbyRiq-kggz",
    "outputId": "02ed9d4e-8cb0-44e0-85f1-69c705720b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainsep.py\n"
     ]
    }
   ],
   "source": [
    "%%file trainsep.py\n",
    "\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"Recipe for training a neural speech separation system on Libri2/3Mix datasets.\n",
    "The system employs an encoder, a decoder, and a masking network.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/sepformer-libri2mix.yaml\n",
    "> python train.py hparams/sepformer-libri3mix.yaml\n",
    "\n",
    "\n",
    "The experiment file is flexible enough to support different neural\n",
    "networks. By properly changing the parameter files, you can try\n",
    "different architectures. The script supports both libri2mix and\n",
    "libri3mix.\n",
    "\n",
    "\n",
    "Authors\n",
    " * Cem Subakan 2020\n",
    " * Mirco Ravanelli 2020\n",
    " * Samuele Cornell 2020\n",
    " * Mirko Bronzi 2020\n",
    " * Jianyuan Zhong 2020\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.core import AMPConfig\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Brain class for speech enhancement training\n",
    "class Seperation(sb.Brain):\n",
    "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        if targets!=[]:\n",
    "            targets = targets[\n",
    "                :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "            ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        try:\n",
    "            mix, _ = mix\n",
    "        except:\n",
    "            pass\n",
    "        mix = mix.to(self.device)\n",
    "\n",
    "        # Convert targets to tensor\n",
    "        if len(targets) != 0:\n",
    "            targets = torch.cat(\n",
    "                [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "                dim=-1,\n",
    "            ).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                if self.hparams.limit_training_signal_len:\n",
    "                    mix, targets = self.cut_signals(mix, targets)\n",
    "\n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n",
    "        sep_h = mix_w * est_mask\n",
    "\n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_spks)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # T changed after conv1d in encoder, fix it here\n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "        # print(est_source.shape,targets.shape)\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the si-snr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "        targets = [batch.vocals, batch.drums]\n",
    "        predictions, targets = self.compute_forward(\n",
    "            mixture, targets, sb.Stage.TRAIN\n",
    "        )\n",
    "        loss = self.compute_objectives(predictions, targets)\n",
    "        loss = loss.mean()\n",
    "        if (\n",
    "            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
    "        ):  # the fix for computational problems\n",
    "            loss.backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up statistics trackers for this stage\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        # snt_id = batch.id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.vocals, batch.drums]\n",
    "        # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(batch.name, mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(batch.name, mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]},\n",
    "                min_keys=[\"si-snr\"],\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "    def save_results(self, test_data):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "            test_data, **self.hparams.dataloader_opts\n",
    "        )\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.name\n",
    "                    # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "                    targets = [batch.vocals, batch.drums]\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    cut_mix,_ = self.cut_signals(mixture,[])\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [cut_mix] * self.hparams.num_spks, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    print(mixture_signal.shape)\n",
    "                    print(targets.shape)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "                    try:\n",
    "                        # Compute SDR\n",
    "                        sdr, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            predictions[0].t().detach().cpu().numpy(),\n",
    "                        )\n",
    "    \n",
    "                        sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                        )\n",
    "\n",
    "                        sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "                        # Saving on a csv file\n",
    "                        row = {\n",
    "                            \"snt_id\": snt_id,\n",
    "                            \"sdr\": sdr.mean(),\n",
    "                            \"sdr_i\": sdr_i,\n",
    "                            \"si-snr\": -sisnr.item(),\n",
    "                            \"si-snr_i\": -sisnr_i.item(),\n",
    "                        }\n",
    "                        writer.writerow(row)\n",
    "\n",
    "                        # Metric Accumulation\n",
    "                        all_sdrs.append(sdr.mean())\n",
    "                        all_sdrs_i.append(sdr_i.mean())\n",
    "                        all_sisnrs.append(-sisnr.item())\n",
    "                        all_sisnrs_i.append(-sisnr_i.item())\n",
    "                    except ValueError as e:\n",
    "                        # Catch potential mir_eval errors that might still occur in edge cases\n",
    "                        print(f\"Error processing sample {snt_id}: {e}\")\n",
    "\n",
    "                row = {\n",
    "                    \"snt_id\": \"avg\",\n",
    "                    \"sdr\": np.array(all_sdrs).mean(),\n",
    "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "        \n",
    "        \n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_spks):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            if len(targets)!=0:\n",
    "                signal = targets[0, :, ns]\n",
    "                signal = signal / signal.abs().max()\n",
    "                save_file = os.path.join(\n",
    "                    save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "                )\n",
    "                torchaudio.save(\n",
    "                    save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "                )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "        \n",
    "    def infer_audio(self, path):\n",
    "        audio, info_rate = torchaudio.load(path)\n",
    "        print(audio.shape)\n",
    "        mix_sig = torchaudio.functional.resample(audio, info_rate, self.hparams.sample_rate)\n",
    "        mix_sig=mix_sig[0,:]\n",
    "        if mix_sig.ndim == 1:\n",
    "             mix_sig = mix_sig.unsqueeze(0)\n",
    "        print(mix_sig.shape)\n",
    "\n",
    "        final_output = torch.empty(0, 2, device=self.device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            audio_len = mix_sig.shape[1]\n",
    "            segment_len = self.hparams.training_signal_len\n",
    "\n",
    "            for i in range(0, audio_len, segment_len):\n",
    "                end_index = min(i + segment_len, audio_len)\n",
    "\n",
    "                current_segment = mix_sig[:, i:end_index]\n",
    "\n",
    "                current_segment = current_segment.to(self.device)\n",
    "                print(current_segment.shape)\n",
    "                est, targets = self.compute_forward(current_segment, [], sb.Stage.VALID)\n",
    "\n",
    "                if est.ndim != 2 or est.shape[1] != 2:\n",
    "                     if est.ndim == 3 and est.shape[2] == 2:\n",
    "                         est = est.squeeze(0)\n",
    "                     elif est.ndim == 3 and est.shape[1] == 2:\n",
    "                          est = est.squeeze(0).transpose(0, 1)\n",
    "                     else:\n",
    "                        raise ValueError(f\"Expected estimated segment shape to be (time, 2) or (batch, time, 2) or (batch, 2, time), but got {est.shape}\")\n",
    "\n",
    "\n",
    "                est = est.to(final_output.device)\n",
    "\n",
    "                final_output = torch.cat((final_output, est), dim=0)\n",
    "        \n",
    "        self.save_audio(\"test_output\", torch.unsqueeze(mix_sig,0).cpu(),[],torch.unsqueeze(final_output,0).cpu())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"Creates data processing pipeline\"\"\"\n",
    "    import musdb\n",
    "    mus_train = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='train')\n",
    "    mus_valid = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='valid')\n",
    "    mus_test = musdb.DB(root=\"/notebooks/musdb18\", subsets=\"test\")\n",
    "    train_data = {}\n",
    "    valid_data= {}\n",
    "    test_data = {}\n",
    "    i = 0;\n",
    "    for track in mus_train:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        train_data[track.name] = dataobj\n",
    "\n",
    "    i = 0;\n",
    "    for track in mus_valid:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        valid_data[track.name] = dataobj\n",
    "\n",
    "    i = 0;\n",
    "    for track in mus_test:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        test_data[track.name] = dataobj\n",
    "\n",
    "    datasets = [\n",
    "        sb.dataio.dataset.DynamicItemDataset(train_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(valid_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(test_data)\n",
    "    ]\n",
    "\n",
    "    @sb.utils.data_pipeline.takes(\"track\")\n",
    "    @sb.utils.data_pipeline.provides(\"name\",\"mix_sig\", \"vocals\",\"drums\",\"bass\",\"other\")\n",
    "    def audio_pipeline_mix(track):\n",
    "        name = track.name\n",
    "\n",
    "        mix_sig = torch.from_numpy(track.audio.T).float()\n",
    "        mix_sig= torchaudio.functional.resample(mix_sig,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        vocals = torch.from_numpy(track.sources['vocals'].audio.T).float()\n",
    "        vocals = torchaudio.functional.resample(vocals,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        drums = torch.from_numpy(track.sources['drums'].audio.T).float()\n",
    "        drums = torchaudio.functional.resample(drums,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        bass = torch.from_numpy(track.sources['bass'].audio.T).float()\n",
    "        bass = torchaudio.functional.resample(bass,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        other = torch.from_numpy(track.sources['other'].audio.T).float()\n",
    "        other= torchaudio.functional.resample(other,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "\n",
    "        return name,mix_sig, vocals,drums,bass,other\n",
    "\n",
    "    # @sb.utils.data_pipeline.takes(\"s1_wav\")\n",
    "    # @sb.utils.data_pipeline.provides(\"s1_sig\")\n",
    "    # def audio_pipeline_s1(s1_wav):\n",
    "    #     s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n",
    "    #     return s1_sig\n",
    "\n",
    "    # @sb.utils.data_pipeline.takes(\"s2_wav\")\n",
    "    # @sb.utils.data_pipeline.provides(\"s2_sig\")\n",
    "    # def audio_pipeline_s2(s2_wav):\n",
    "    #     s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n",
    "    #     return s2_sig\n",
    "\n",
    "    # if hparams[\"num_spks\"] == 3:\n",
    "\n",
    "    #     @sb.utils.data_pipeline.takes(\"s3_wav\")\n",
    "    #     @sb.utils.data_pipeline.provides(\"s3_sig\")\n",
    "    #     def audio_pipeline_s3(s3_wav):\n",
    "    #         s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n",
    "    #         return s3_sig\n",
    "\n",
    "    # if hparams[\"use_wham_noise\"]:\n",
    "\n",
    "    #     @sb.utils.data_pipeline.takes(\"noise_wav\")\n",
    "    #     @sb.utils.data_pipeline.provides(\"noise_sig\")\n",
    "    #     def audio_pipeline_noise(noise_wav):\n",
    "    #         noise_sig = sb.dataio.dataio.read_audio(noise_wav)\n",
    "    #         return noise_sig\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n",
    "    # sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1unzip ../wham_noise.zip -d /wham/)\n",
    "    # sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n",
    "    # if hparams[\"num_spks\"] == 3:\n",
    "    #     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n",
    "\n",
    "    # if hparams[\"use_wham_noise\"]:\n",
    "    #     print(\"Using the WHAM! noise in the data pipeline\")\n",
    "    #     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_noise)\n",
    "\n",
    "    # if (hparams[\"num_spks\"] == 2) and hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"noise_sig\"]\n",
    "    #     )\n",
    "    # elif (hparams[\"num_spks\"] == 3) and hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets,\n",
    "    #         [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\", \"noise_sig\"],\n",
    "    #     )\n",
    "    # elif (hparams[\"num_spks\"] == 2) and not hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\"]\n",
    "    #     )\n",
    "    # else:\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        # datasets, [\"name\", \"mix_sig\", \"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "        datasets, [\"name\", \"mix_sig\", \"vocals\", \"drums\"]\n",
    "    )\n",
    "\n",
    "    return datasets[0], datasets[1], datasets[2]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Data preparation\n",
    "    train_data, valid_data, test_data = dataio_prep(hparams)\n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Seperation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "    # separator.infer_audio(\"/notebooks/musdb18/test/Al James - Schoolboy Facination.stem.mp4\")\n",
    "\n",
    "\n",
    "    # Training\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_data,\n",
    "        valid_data,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # Eval\n",
    "    separator.evaluate(test_data, min_key=\"si-snr\")\n",
    "    separator.save_results(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:52:38.131663Z",
     "iopub.status.busy": "2025-04-23T02:52:38.131082Z",
     "iopub.status.idle": "2025-04-23T02:52:38.145810Z",
     "shell.execute_reply": "2025-04-23T02:52:38.145133Z",
     "shell.execute_reply.started": "2025-04-23T02:52:38.131638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Transformersep.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file Transformersep.yaml\n",
    "# ################################\n",
    "# Model: SepFormer for source separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : Libri2mix\n",
    "# ################################\n",
    "#\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "#\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "\n",
    "# e.g. '/yourpath/Libri2Mix/train-clean-360/'\n",
    "# the data folder is needed even if dynamic mixing is applied\n",
    "data_folder: /yourpath/Libri2Mix/train-clean-360/\n",
    "\n",
    "# this is the base folder for dynamic mixing\n",
    "base_folder_dm: /yourpath/LibriSpeech/train-clean-360/\n",
    "\n",
    "experiment_name: sepformer-libri2mix\n",
    "output_folder: !ref results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <save_folder>/libri2mix_train-360.csv\n",
    "valid_data: !ref <save_folder>/libri2mix_dev.csv\n",
    "test_data: !ref <save_folder>/libri2mix_test.csv\n",
    "skip_prep: False\n",
    "\n",
    "ckpt_interval_minutes: 60\n",
    "\n",
    "# Experiment params\n",
    "num_spks: 2\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 16000\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 100\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "# if True, the training sequences are cut to a specified length\n",
    "limit_training_signal_len: True\n",
    "# this is the length of sequences if we choose to limit\n",
    "# the signal length of training sequences\n",
    "training_signal_len: 88000\n",
    "\n",
    "# Set it to True to dynamically create mixtures at training time\n",
    "dynamic_mixing: False\n",
    "use_wham_noise: False\n",
    "\n",
    "# Speed perturbation\n",
    "speed_changes: [95, 100, 105]  # List of speed changes for time-stretching\n",
    "\n",
    "speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n",
    "    orig_freq: !ref <sample_rate>\n",
    "    speeds: !ref <speed_changes>\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "d_ffn: 1024\n",
    "\n",
    "# Dataloader options\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 8\n",
    "\n",
    "\n",
    "# Specifying the network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "\n",
    "SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
    "    num_spks: !ref <num_spks>\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: !ref <out_channels>\n",
    "    num_layers: 2\n",
    "    K: 250\n",
    "    intra_model: !ref <SBtfintra>\n",
    "    inter_model: !ref <SBtfinter>\n",
    "    norm: ln\n",
    "    linear_layer_after_inter_intra: False\n",
    "    skip_around_intra: True\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 5\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        counter: !ref <epoch_counter>\n",
    "        # lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-23T03:02:50.603603Z",
     "iopub.status.busy": "2025-04-23T03:02:50.603380Z",
     "iopub.status.idle": "2025-04-23T03:02:51.476526Z",
     "shell.execute_reply": "2025-04-23T03:02:51.475985Z",
     "shell.execute_reply.started": "2025-04-23T03:02:50.603585Z"
    },
    "id": "7Ds4bGbKLyk7",
    "outputId": "abc9a38e-a3cf-4c7f-ab2b-0c019639e476"
   },
   "outputs": [],
   "source": [
    "!rm -rf results/\n",
    "# !python train.py Transformer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T01:06:33.973795Z",
     "iopub.status.busy": "2025-04-22T01:06:33.973283Z",
     "iopub.status.idle": "2025-04-22T01:06:33.976147Z",
     "shell.execute_reply": "2025-04-22T01:06:33.975608Z",
     "shell.execute_reply.started": "2025-04-22T01:06:33.973776Z"
    },
    "id": "PTbUO-RXIADJ"
   },
   "outputs": [],
   "source": [
    "# !pip install museval openunmix\n",
    "# !python -m openunmix.evaluate --outdir /path/to/musdb/estimates --evaldir /path/to/museval/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T22:29:49.877042Z",
     "iopub.status.busy": "2025-04-22T22:29:49.876281Z",
     "iopub.status.idle": "2025-04-22T22:30:08.987995Z",
     "shell.execute_reply": "2025-04-22T22:30:08.987064Z",
     "shell.execute_reply.started": "2025-04-22T22:29:49.877013Z"
    },
    "id": "aspdXyDyxcJM",
    "outputId": "95c0cfac-7f1a-4679-ee96-8d532ac7fd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source2.wav (deflated 26%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source2.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source1.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_mix.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source2.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source2.wav (deflated 33%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source2.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source2.wav (deflated 1%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_mix.wav (deflated 14%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source2.wav (deflated 36%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source2.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source1.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source2.wav (deflated 58%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_mix.wav (deflated 19%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source2.wav (deflated 21%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_mix.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source1.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source2.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source1.wav (deflated 73%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source1.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source2.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source2.wav (deflated 32%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source2.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source1.wav (deflated 0%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source2.wav (deflated 16%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_mix.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source2.wav (deflated 56%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source1.wav (deflated 46%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source2.wav (deflated 28%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source2.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source1.wav (deflated 25%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source2.wav (deflated 22%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source1.wav (deflated 3%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /notebooks/file.zip /notebooks/results/wavformer-libri2mix/1234/save/audio_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T00:08:53.234966Z",
     "iopub.status.busy": "2025-04-21T00:08:53.234746Z",
     "iopub.status.idle": "2025-04-21T00:08:53.255051Z",
     "shell.execute_reply": "2025-04-21T00:08:53.254672Z",
     "shell.execute_reply.started": "2025-04-21T00:08:53.234950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%file train.py\n",
    "\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"Recipe for training a neural speech separation system on Libri2/3Mix datasets.\n",
    "The system employs an encoder, a decoder, and a masking network.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/sepformer-libri2mix.yaml\n",
    "> python train.py hparams/sepformer-libri3mix.yaml\n",
    "\n",
    "\n",
    "The experiment file is flexible enough to support different neural\n",
    "networks. By properly changing the parameter files, you can try\n",
    "different architectures. The script supports both libri2mix and\n",
    "libri3mix.\n",
    "\n",
    "\n",
    "Authors\n",
    " * Cem Subakan 2020\n",
    " * Mirco Ravanelli 2020\n",
    " * Samuele Cornell 2020\n",
    " * Mirko Bronzi 2020\n",
    " * Jianyuan Zhong 2020\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.core import AMPConfig\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Brain class for speech enhancement training\n",
    "class Seperation(sb.Brain):\n",
    "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        if targets!=[]:\n",
    "            targets = targets[\n",
    "                :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "            ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix\n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
    "\n",
    "        # Convert targets to tensor\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Add speech distortions\n",
    "        # if stage == sb.Stage.TRAIN:\n",
    "        with torch.no_grad():\n",
    "            if self.hparams.limit_training_signal_len:\n",
    "                mix, targets = self.cut_signals(mix, targets)\n",
    "\n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n",
    "        sep_h = mix_w * est_mask\n",
    "\n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_spks)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # T changed after conv1d in encoder, fix it here\n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the si-snr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "        targets = [batch.vocals, batch.drums]\n",
    "        predictions, targets = self.compute_forward(\n",
    "            mixture, targets, sb.Stage.TRAIN\n",
    "        )\n",
    "        loss = self.compute_objectives(predictions, targets)\n",
    "        loss = loss.mean()\n",
    "        if (\n",
    "            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
    "        ):  # the fix for computational problems\n",
    "            loss.backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up statistics trackers for this stage\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        # snt_id = batch.id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.vocals, batch.drums]\n",
    "        # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(batch.name, mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(batch.name, mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]},\n",
    "                min_keys=[\"si-snr\"],\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "    def save_results(self, test_data):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "            test_data, **self.hparams.dataloader_opts\n",
    "        )\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.name\n",
    "                    # targets = [batch.vocals, batch.drums, batch.bass, batch.other]\n",
    "                    targets = [batch.vocals, batch.drums]\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    cut_mix,_ = self.cut_signals(mixture,[])\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [cut_mix] * self.hparams.num_spks, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    print(mixture_signal.shape)\n",
    "                    print(targets.shape)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "\n",
    "                    # Compute SDR\n",
    "                    sdr, _, _, _ = bss_eval_sources(\n",
    "                        targets[0].t().cpu().numpy(),\n",
    "                        predictions[0].t().detach().cpu().numpy(),\n",
    "                    )\n",
    "\n",
    "                    sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                        targets[0].t().cpu().numpy(),\n",
    "                        mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                    )\n",
    "\n",
    "                    sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "                    # Saving on a csv file\n",
    "                    row = {\n",
    "                        \"snt_id\": snt_id,\n",
    "                        \"sdr\": sdr.mean(),\n",
    "                        \"sdr_i\": sdr_i,\n",
    "                        \"si-snr\": -sisnr.item(),\n",
    "                        \"si-snr_i\": -sisnr_i.item(),\n",
    "                    }\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                    # Metric Accumulation\n",
    "                    all_sdrs.append(sdr.mean())\n",
    "                    all_sdrs_i.append(sdr_i.mean())\n",
    "                    all_sisnrs.append(-sisnr.item())\n",
    "                    all_sisnrs_i.append(-sisnr_i.item())\n",
    "\n",
    "                row = {\n",
    "                    \"snt_id\": \"avg\",\n",
    "                    \"sdr\": np.array(all_sdrs).mean(),\n",
    "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_spks):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"Creates data processing pipeline\"\"\"\n",
    "    import musdb\n",
    "    mus_train = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='train')\n",
    "    mus_valid = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='valid')\n",
    "    mus_test = musdb.DB(root=\"/notebooks/musdb18\", subsets=\"test\")\n",
    "    train_data = {}\n",
    "    valid_data= {}\n",
    "    test_data = {}\n",
    "    i = 0;\n",
    "    for track in mus_train:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        train_data[track.name] = dataobj\n",
    "\n",
    "    i = 0;\n",
    "    for track in mus_valid:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        valid_data[track.name] = dataobj\n",
    "\n",
    "    i = 0;\n",
    "    for track in mus_test:\n",
    "        i+=1\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        test_data[track.name] = dataobj\n",
    "\n",
    "    datasets = [\n",
    "        sb.dataio.dataset.DynamicItemDataset(train_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(valid_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(test_data)\n",
    "    ]\n",
    "\n",
    "    @sb.utils.data_pipeline.takes(\"track\")\n",
    "    @sb.utils.data_pipeline.provides(\"name\",\"mix_sig\", \"vocals\",\"drums\",\"bass\",\"other\")\n",
    "    def audio_pipeline_mix(track):\n",
    "        name = track.name\n",
    "\n",
    "        mix_sig = torch.from_numpy(track.audio.T).float()\n",
    "        mix_sig= torchaudio.functional.resample(mix_sig,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        vocals = torch.from_numpy(track.sources['vocals'].audio.T).float()\n",
    "        vocals = torchaudio.functional.resample(vocals,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        drums = torch.from_numpy(track.sources['drums'].audio.T).float()\n",
    "        drums = torchaudio.functional.resample(drums,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        bass = torch.from_numpy(track.sources['bass'].audio.T).float()\n",
    "        bass = torchaudio.functional.resample(bass,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "        other = torch.from_numpy(track.sources['other'].audio.T).float()\n",
    "        other= torchaudio.functional.resample(other,track.rate,hparams['sample_rate'])[1,:]\n",
    "\n",
    "\n",
    "        return name,mix_sig, vocals,drums,bass,other\n",
    "\n",
    "    # @sb.utils.data_pipeline.takes(\"s1_wav\")\n",
    "    # @sb.utils.data_pipeline.provides(\"s1_sig\")\n",
    "    # def audio_pipeline_s1(s1_wav):\n",
    "    #     s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n",
    "    #     return s1_sig\n",
    "\n",
    "    # @sb.utils.data_pipeline.takes(\"s2_wav\")\n",
    "    # @sb.utils.data_pipeline.provides(\"s2_sig\")\n",
    "    # def audio_pipeline_s2(s2_wav):\n",
    "    #     s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n",
    "    #     return s2_sig\n",
    "\n",
    "    # if hparams[\"num_spks\"] == 3:\n",
    "\n",
    "    #     @sb.utils.data_pipeline.takes(\"s3_wav\")\n",
    "    #     @sb.utils.data_pipeline.provides(\"s3_sig\")\n",
    "    #     def audio_pipeline_s3(s3_wav):\n",
    "    #         s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n",
    "    #         return s3_sig\n",
    "\n",
    "    # if hparams[\"use_wham_noise\"]:\n",
    "\n",
    "    #     @sb.utils.data_pipeline.takes(\"noise_wav\")\n",
    "    #     @sb.utils.data_pipeline.provides(\"noise_sig\")\n",
    "    #     def audio_pipeline_noise(noise_wav):\n",
    "    #         noise_sig = sb.dataio.dataio.read_audio(noise_wav)\n",
    "    #         return noise_sig\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n",
    "    # sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1unzip ../wham_noise.zip -d /wham/)\n",
    "    # sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n",
    "    # if hparams[\"num_spks\"] == 3:\n",
    "    #     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n",
    "\n",
    "    # if hparams[\"use_wham_noise\"]:\n",
    "    #     print(\"Using the WHAM! noise in the data pipeline\")\n",
    "    #     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_noise)\n",
    "\n",
    "    # if (hparams[\"num_spks\"] == 2) and hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"noise_sig\"]\n",
    "    #     )\n",
    "    # elif (hparams[\"num_spks\"] == 3) and hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets,\n",
    "    #         [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\", \"noise_sig\"],\n",
    "    #     )\n",
    "    # elif (hparams[\"num_spks\"] == 2) and not hparams[\"use_wham_noise\"]:\n",
    "    #     sb.dataio.dataset.set_output_keys(\n",
    "    #         datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\"]\n",
    "    #     )\n",
    "    # else:\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        # datasets, [\"name\", \"mix_sig\", \"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "        datasets, [\"name\", \"mix_sig\", \"vocals\", \"drums\"]\n",
    "    )\n",
    "\n",
    "    return datasets[0], datasets[1], datasets[2]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Data preparation\n",
    "    train_data, valid_data, test_data = dataio_prep(hparams)\n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Seperation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    # Training\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_data,\n",
    "        valid_data,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # Eval\n",
    "    separator.evaluate(test_data, min_key=\"si-snr\")\n",
    "    separator.save_results(test_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5211204,
     "sourceId": 8817844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
