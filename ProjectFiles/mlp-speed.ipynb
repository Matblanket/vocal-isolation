{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-25T03:09:14.625947Z",
     "iopub.status.busy": "2025-04-25T03:09:14.625726Z",
     "iopub.status.idle": "2025-04-25T03:09:14.637997Z",
     "shell.execute_reply": "2025-04-25T03:09:14.637492Z",
     "shell.execute_reply.started": "2025-04-25T03:09:14.625924Z"
    },
    "id": "OWbyRiq-kggz",
    "outputId": "02ed9d4e-8cb0-44e0-85f1-69c705720b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainmoespeed.py\n"
     ]
    }
   ],
   "source": [
    "%%file trainmoespeed.py\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"Recipe for training a neural speech separation system on Libri2/3Mix datasets.\n",
    "The system employs an encoder, a decoder, and a masking network.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/sepformer-libri2mix.yaml\n",
    "> python train.py hparams/sepformer-libri3mix.yaml\n",
    "\n",
    "\n",
    "The experiment file is flexible enough to support different neural\n",
    "networks. By properly changing the parameter files, you can try\n",
    "different architectures. The script supports both libri2mix and\n",
    "libri3mix.\n",
    "\n",
    "\n",
    "Authors\n",
    " * Cem Subakan 2020\n",
    " * Mirco Ravanelli 2020\n",
    " * Samuele Cornell 2020\n",
    " * Mirko Bronzi 2020\n",
    " * Jianyuan Zhong 2020\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Define training procedure\n",
    "class Separation(sb.Brain):\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix\n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
    "        # Convert targets to tensor\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Add speech distortions\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            with torch.no_grad():\n",
    "                if self.hparams.use_speedperturb or self.hparams.use_rand_shift:\n",
    "                    mix, targets = self.add_speed_perturb(targets, mix_lens)\n",
    "\n",
    "                    mix = targets.sum(-1)\n",
    "\n",
    "                if self.hparams.use_wavedrop:\n",
    "                    mix = self.hparams.drop_chunk(mix, mix_lens)\n",
    "                    mix = self.hparams.drop_freq(mix)\n",
    "\n",
    "                if self.hparams.limit_training_signal_len:\n",
    "                    mix, targets = self.cut_signals(mix, targets)\n",
    "\n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        \n",
    "        est_mask = est_mask.permute(1, 0, 2, 3)\n",
    "        g1_scores = self.hparams.SPK_Scores1(est_mask[:,0:10, :, :])\n",
    "        g2_scores = self.hparams.SPK_Scores2(est_mask[:,10:20, :, :])\n",
    "        est_mask = est_mask.permute(1, 0, 2, 3)\n",
    "        topk_indices = torch.topk(g1_scores, k=4, dim=1).indices\n",
    "        selected_masks = torch.squeeze(est_mask[topk_indices, :, :, :],0)\n",
    "        group1_masks = torch.prod(selected_masks, dim=0)\n",
    "        topk_indices = torch.topk(g2_scores, k=4, dim=1).indices + 10\n",
    "        selected_masks = torch.squeeze(est_mask[topk_indices, :, :, :],0)\n",
    "        group2_masks = torch.prod(selected_masks, dim=0)\n",
    "        est_mask = torch.stack([group1_masks,group2_masks])\n",
    "        \n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n",
    "        sep_h = mix_w * est_mask\n",
    "\n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_spks)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # T changed after conv1d in encoder, fix it here\n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the si-snr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.vocals, batch.accompaniment]\n",
    "        noise = None\n",
    "        with self.training_ctx:\n",
    "            predictions, targets = self.compute_forward(\n",
    "                mixture, targets, sb.Stage.TRAIN, noise\n",
    "            )\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "            # hard threshold the easy dataitems\n",
    "            if self.hparams.threshold_byloss:\n",
    "                th = self.hparams.threshold\n",
    "                loss = loss[loss > th]\n",
    "                if loss.nelement() > 0:\n",
    "                    loss = loss.mean()\n",
    "            else:\n",
    "                loss = loss.mean()\n",
    "\n",
    "        if loss.nelement() > 0 and loss < self.hparams.loss_upper_lim:\n",
    "            self.scaler.scale(loss).backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        snt_id = batch.name\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.vocals, batch.accompaniment]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(snt_id, mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(snt_id, mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]},\n",
    "                min_keys=[\"si-snr\"],\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "    def add_speed_perturb(self, targets, targ_lens):\n",
    "        original_len = targets.shape[1]\n",
    "        num_sources = targets.shape[-1]\n",
    "        processed_targets_list = []\n",
    "    \n",
    "        for i in range(num_sources):\n",
    "            current_source = targets[:, :, i]\n",
    "    \n",
    "            processed_source = current_source\n",
    "    \n",
    "            if self.hparams.use_speedperturb:\n",
    "                processed_source = self.hparams.speed_perturb(current_source)\n",
    "    \n",
    "                if self.hparams.use_rand_shift:\n",
    "                     max_shift_actual = min(self.hparams.max_shift, processed_source.shape[1])\n",
    "                     min_shift_actual = max(self.hparams.min_shift, -processed_source.shape[1])\n",
    "    \n",
    "                     if max_shift_actual > min_shift_actual:\n",
    "                         rand_shift = torch.randint(\n",
    "                             min_shift_actual, max_shift_actual + 1, (1,),\n",
    "                             device=processed_source.device\n",
    "                         )\n",
    "                         processed_source = torch.roll(\n",
    "                             processed_source, shifts=(rand_shift[0].item(),), dims=1\n",
    "                         )\n",
    "    \n",
    "            current_len = processed_source.shape[1]\n",
    "    \n",
    "            if current_len > original_len:\n",
    "                processed_source = processed_source[:, :original_len]\n",
    "    \n",
    "            elif current_len < original_len:\n",
    "                padding_needed = original_len - current_len\n",
    "                padding_sequence = processed_source[:, -padding_needed:]\n",
    "                processed_source = torch.cat((processed_source, padding_sequence), dim=1)\n",
    "    \n",
    "            processed_targets_list.append(processed_source.to(targets.device))\n",
    "    \n",
    "        targets = torch.stack(processed_targets_list, dim=-1)\n",
    "    \n",
    "        mix = targets.sum(dim=-1)\n",
    "    \n",
    "        return mix, targets\n",
    "\n",
    "\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        targets = targets[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "        ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def reset_layer_recursively(self, layer):\n",
    "        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "        for child_layer in layer.modules():\n",
    "            if layer != child_layer:\n",
    "                self.reset_layer_recursively(child_layer)\n",
    "\n",
    "    def save_results(self, test_data):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "            test_data, **self.hparams.dataloader_opts\n",
    "        )\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.name\n",
    "                    targets = [batch.vocals, batch.accompaniment]\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [mixture] * self.hparams.num_spks, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        # Compute SDR\n",
    "                        sdr, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            predictions[0].t().detach().cpu().numpy(),\n",
    "                        )\n",
    "    \n",
    "                        sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                        )\n",
    "\n",
    "                        sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "                        # Saving on a csv file\n",
    "                        row = {\n",
    "                            \"snt_id\": snt_id,\n",
    "                            \"sdr\": sdr.mean(),\n",
    "                            \"sdr_i\": sdr_i,\n",
    "                            \"si-snr\": -sisnr.item(),\n",
    "                            \"si-snr_i\": -sisnr_i.item(),\n",
    "                        }\n",
    "                        writer.writerow(row)\n",
    "\n",
    "                        # Metric Accumulation\n",
    "                        all_sdrs.append(sdr.mean())\n",
    "                        all_sdrs_i.append(sdr_i.mean())\n",
    "                        all_sisnrs.append(-sisnr.item())\n",
    "                        all_sisnrs_i.append(-sisnr_i.item())\n",
    "                    except ValueError as e:\n",
    "                        # Catch potential mir_eval errors that might still occur in edge cases\n",
    "                        print(f\"Error processing sample {snt_id}: {e}\")\n",
    "\n",
    "                row = {\n",
    "                    \"snt_id\": \"avg\",\n",
    "                    \"sdr\": np.array(all_sdrs).mean(),\n",
    "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_spks):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"Creates data processing pipeline\"\"\"\n",
    "    import musdb\n",
    "    import random\n",
    "    mus_train = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='train', sample_rate = hparams['sample_rate'])\n",
    "    mus_valid = musdb.DB(root=\"/notebooks/musdb18\",subsets=\"train\", split='valid', sample_rate = hparams['sample_rate'])\n",
    "    mus_test = musdb.DB(root=\"/notebooks/musdb18\", subsets=\"test\", sample_rate = hparams['sample_rate'])\n",
    "    train_data = {}\n",
    "    valid_data= {}\n",
    "    test_data = {}\n",
    "    for track in mus_train:\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        train_data[track.name] = dataobj\n",
    "\n",
    "    for track in mus_valid:\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        valid_data[track.name] = dataobj\n",
    "\n",
    "    for track in mus_test:\n",
    "        dataobj={}\n",
    "        dataobj['track'] = track\n",
    "        test_data[track.name] = dataobj\n",
    "\n",
    "    datasets = [\n",
    "        sb.dataio.dataset.DynamicItemDataset(train_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(valid_data),\n",
    "        sb.dataio.dataset.DynamicItemDataset(test_data)\n",
    "    ]\n",
    "\n",
    "    @sb.utils.data_pipeline.takes(\"track\")\n",
    "    @sb.utils.data_pipeline.provides(\"name\",\"mix_sig\", \"vocals\",\"accompaniment\")\n",
    "    def audio_pipeline_mix(track):\n",
    "        name = track.name\n",
    "        track.chunk_duration = hparams[\"audio_length\"]\n",
    "        track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n",
    "\n",
    "        mix_sig = torch.from_numpy(track.audio.T)[1].float()\n",
    "\n",
    "        vocals = torch.from_numpy(track.sources['vocals'].audio.T)[1].float()\n",
    "\n",
    "        accompaniment = torch.from_numpy(track.targets['accompaniment'].audio.T)[1].float()\n",
    "        return name,mix_sig, vocals,accompaniment\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        datasets, [\"name\", \"mix_sig\", \"vocals\", \"accompaniment\"]\n",
    "    )\n",
    "\n",
    "    return datasets[0], datasets[1], datasets[2]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "    run_opts['device']=\"cuda\"\n",
    "    print(run_opts)\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
    "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "        hparams[\"precision\"] = \"bf16\"\n",
    "    \n",
    "    train_data, valid_data, test_data = dataio_prep(hparams)\n",
    "\n",
    "    # Load pretrained model if pretrained_separator is present in the yaml\n",
    "    if \"pretrained_separator\" in hparams:\n",
    "        run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
    "        hparams[\"pretrained_separator\"].load_collected()\n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Separation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "    \n",
    "    # re-initialize the parameters if we don't use a pretrained model\n",
    "    if \"pretrained_separator\" not in hparams:\n",
    "        for module in separator.modules.values():\n",
    "            separator.reset_layer_recursively(module)\n",
    "\n",
    "    # Training\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_data,\n",
    "        valid_data,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # Eval\n",
    "    separator.evaluate(test_data, min_key=\"si-snr\")\n",
    "    separator.save_results(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T02:06:49.872737Z",
     "iopub.status.busy": "2025-04-25T02:06:49.872498Z",
     "iopub.status.idle": "2025-04-25T02:06:49.880808Z",
     "shell.execute_reply": "2025-04-25T02:06:49.880375Z",
     "shell.execute_reply.started": "2025-04-25T02:06:49.872717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Transformermoespeed.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file Transformermoespeed.yaml\n",
    "# ################################\n",
    "# Model: SepFormer for source separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : Libri2mix\n",
    "# ################################\n",
    "#\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "#\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "\n",
    "# e.g. '/yourpath/Libri2Mix/train-clean-360/'\n",
    "# the data folder is needed even if dynamic mixing is applied\n",
    "data_folder: /yourpath/Libri2Mix/train-clean-360/\n",
    "\n",
    "experiment_name: moespeed-scored-former-libri2mix\n",
    "output_folder: !ref results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <save_folder>/libri2mix_train-360.csv\n",
    "valid_data: !ref <save_folder>/libri2mix_dev.csv\n",
    "test_data: !ref <save_folder>/libri2mix_test.csv\n",
    "skip_prep: False\n",
    "\n",
    "ckpt_interval_minutes: 60\n",
    "\n",
    "# Experiment params\n",
    "precision: fp16 # bf16, fp16 or fp32 # Set it to True for mixed precision\n",
    "num_spks: 2\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 16000\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 100\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "# if True, the training sequences are cut to a specified length\n",
    "limit_training_signal_len: False\n",
    "# this is the length of sequences if we choose to limit\n",
    "# the signal length of training sequences\n",
    "training_signal_len: 57000\n",
    "audio_length: 6\n",
    "\n",
    "\n",
    "# Parameters for data augmentation\n",
    "use_wavedrop: True\n",
    "use_speedperturb: True\n",
    "use_rand_shift: True\n",
    "min_shift: -8000\n",
    "max_shift: 8000\n",
    "\n",
    "# Speed perturbation\n",
    "speed_changes: [95, 100, 105]  # List of speed changes for time-stretching\n",
    "\n",
    "speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n",
    "    orig_freq: !ref <sample_rate>\n",
    "    speeds: !ref <speed_changes>\n",
    "\n",
    "# Frequency drop: randomly drops a number of frequency bands to zero.\n",
    "drop_freq_low: 0  # Min frequency band dropout probability\n",
    "drop_freq_high: 1  # Max frequency band dropout probability\n",
    "drop_freq_count_low: 1  # Min number of frequency bands to drop\n",
    "drop_freq_count_high: 3  # Max number of frequency bands to drop\n",
    "drop_freq_width: 0.05  # Width of frequency bands to drop\n",
    "\n",
    "drop_freq: !new:speechbrain.augment.time_domain.DropFreq\n",
    "    drop_freq_low: !ref <drop_freq_low>\n",
    "    drop_freq_high: !ref <drop_freq_high>\n",
    "    drop_freq_count_low: !ref <drop_freq_count_low>\n",
    "    drop_freq_count_high: !ref <drop_freq_count_high>\n",
    "    drop_freq_width: !ref <drop_freq_width>\n",
    "\n",
    "# Time drop: randomly drops a number of temporal chunks.\n",
    "drop_chunk_count_low: 1  # Min number of audio chunks to drop\n",
    "drop_chunk_count_high: 5  # Max number of audio chunks to drop\n",
    "drop_chunk_length_low: 1000  # Min length of audio chunks to drop\n",
    "drop_chunk_length_high: 2000  # Max length of audio chunks to drop\n",
    "\n",
    "drop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n",
    "    drop_length_low: !ref <drop_chunk_length_low>\n",
    "    drop_length_high: !ref <drop_chunk_length_high>\n",
    "    drop_count_low: !ref <drop_chunk_count_low>\n",
    "    drop_count_high: !ref <drop_chunk_count_high>\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "d_ffn: 1024\n",
    "dropout: 0.5\n",
    "dnn_neurons: 512\n",
    "\n",
    "# Dataloader options\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 8\n",
    "\n",
    "\n",
    "# Specifying the network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "\n",
    "SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 8\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 8\n",
    "    d_ffn: !ref <d_ffn>\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
    "    num_spks: !ref <num_spks> * 10\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: !ref <out_channels>\n",
    "    num_layers: 2\n",
    "    K: 250\n",
    "    intra_model: !ref <SBtfintra>\n",
    "    inter_model: !ref <SBtfinter>\n",
    "    norm: ln\n",
    "    linear_layer_after_inter_intra: False\n",
    "    skip_around_intra: True\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "SPK_Scores1: !new:speechbrain.nnet.containers.Sequential\n",
    "    input_shape: [1, 10, 256 ,11999] \n",
    "    linear1: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: !ref <dnn_neurons>\n",
    "        bias: True\n",
    "    activation: !new:torch.nn.LeakyReLU\n",
    "    drop: !new:torch.nn.Dropout\n",
    "        p: !ref <dropout>\n",
    "    linear2: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: !ref <dnn_neurons>\n",
    "        bias: True\n",
    "    activation2: !new:torch.nn.LeakyReLU\n",
    "    drop2: !new:torch.nn.Dropout\n",
    "        p: !ref <dropout>\n",
    "\n",
    "    flatten: !new:torch.nn.Flatten\n",
    "        start_dim: 1\n",
    "\n",
    "    linear_out: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: 10\n",
    "        bias: True\n",
    "\n",
    "SPK_Scores2: !new:speechbrain.nnet.containers.Sequential\n",
    "    input_shape: [1, 10, 256 ,11999] # Input shape: [Batch, Channel, Feature1, Feature2]\n",
    "    linear1: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: !ref <dnn_neurons>\n",
    "        bias: True\n",
    "    # bn1: !name:speechbrain.nnet.normalization.BatchNorm1d\n",
    "    activation: !new:torch.nn.LeakyReLU\n",
    "    drop: !new:torch.nn.Dropout\n",
    "        p: !ref <dropout>\n",
    "    linear2: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: !ref <dnn_neurons>\n",
    "        bias: True\n",
    "    # bn2: !name:speechbrain.nnet.normalization.BatchNorm1d\n",
    "    activation2: !new:torch.nn.LeakyReLU\n",
    "    drop2: !new:torch.nn.Dropout\n",
    "        p: !ref <dropout>\n",
    "\n",
    "    # --- Layers added to achieve [Batch, 10] output ---\n",
    "    # At this point, the shape is [10, 1, 256, dnn_neurons]\n",
    "    flatten: !new:torch.nn.Flatten\n",
    "        # Flatten from the dimension after the batch dimension (dim 1)\n",
    "        # This collapses [1, 256, dnn_neurons] into a single dimension\n",
    "        start_dim: 1\n",
    "    # Shape after flatten: [10, 1 * 256 * dnn_neurons] (e.g., [10, 256 * dnn_neurons])\n",
    "\n",
    "    linear_out: !name:speechbrain.nnet.linear.Linear\n",
    "        # This final linear layer projects the flattened features to 10 scores\n",
    "        n_neurons: 10\n",
    "        bias: True\n",
    "    # Shape after linear_out: [10, 10] (Matches the desired output shape)\n",
    "    \n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 5\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "    spk_scores1: !ref <SPK_Scores1>\n",
    "    spk_scores2: !ref <SPK_Scores2>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        spk_scores1: !ref <SPK_Scores1>\n",
    "        spk_scores2: !ref <SPK_Scores2>\n",
    "        counter: !ref <epoch_counter>\n",
    "        # lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T11:58:42.985162Z",
     "iopub.status.busy": "2025-04-24T11:58:42.984042Z",
     "iopub.status.idle": "2025-04-24T11:58:42.988982Z",
     "shell.execute_reply": "2025-04-24T11:58:42.987777Z",
     "shell.execute_reply.started": "2025-04-24T11:58:42.985129Z"
    },
    "id": "PTbUO-RXIADJ"
   },
   "outputs": [],
   "source": [
    "# !pip install museval openunmix\n",
    "# !python -m openunmix.evaluate --outdir /path/to/musdb/estimates --evaldir /path/to/museval/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T22:29:49.877042Z",
     "iopub.status.busy": "2025-04-22T22:29:49.876281Z",
     "iopub.status.idle": "2025-04-22T22:30:08.987995Z",
     "shell.execute_reply": "2025-04-22T22:30:08.987064Z",
     "shell.execute_reply.started": "2025-04-22T22:29:49.877013Z"
    },
    "id": "aspdXyDyxcJM",
    "outputId": "95c0cfac-7f1a-4679-ee96-8d532ac7fd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source2.wav (deflated 26%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source2.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source1.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_mix.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source2.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source2.wav (deflated 33%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source2.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source2.wav (deflated 1%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_mix.wav (deflated 14%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source2.wav (deflated 36%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source2.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source1.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source2.wav (deflated 58%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_mix.wav (deflated 19%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Ben Carrigan - We'll Talk About It All Tonight\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source2.wav (deflated 21%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_mix.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source1.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source2.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source2.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source1.wav (deflated 73%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_source1.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Timboz - Pony']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Too Much']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source2.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Oh No']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Doppler Shift - Atrophy']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source2.wav (deflated 32%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Broken Man']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source2.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Arise - Run Run Run']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Louis Cressy Band - Good Time']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Mountaineering Club - Mallory']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Buitraker - Revo X']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Long Wait - Dark Horses']_source1.wav (deflated 0%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source2.wav (deflated 16%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['James Elder & Mark M Thompson - The English Actor']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Raft Monk - Tiring']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises - Falcon 69']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Motor Tapes - Shore']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['We Fell From The Sky - Not You']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Lyndsey Ollard - Catching Up']_mix.wav (deflated 15%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Enda Reilly - Cur An Long Ag Seol']_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source1.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Cristina Vane - So Easy']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Nerve 9 - Pray For The Rain']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Hollow Ground - Ill Fate']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Speak Softly - Like Horses']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Bobby Nobody - Stitch Up']_source1.wav (deflated 5%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Forkupines - Semantics']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['BKS - Bulldozer']_source2.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source1.wav (deflated 2%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Angels In Amplifiers - I'm Alright\"]_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Detsky Sad - Walkie Talkie']_source2.wav (deflated 56%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Moosmusic - Big Dummy Shake']_mix.wav (deflated 8%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Juliet's Rescue - Heartbeats\"]_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Side Effects Project - Sing With Me']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Skelpolu - Resurrection']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Georgia Wonder - Siren']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Al James - Schoolboy Facination']_source1.wav (deflated 46%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['M.E.R.C. Music - Knockout']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Signe Jakobsen - What Have You Done To Me']_mix.wav (deflated 12%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Tom McKenzie - Directions']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Mu - Too Bright']_source2.wav (deflated 28%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Zeno - Signs']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Over The Top']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us']_source1.wav (deflated 3%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source2.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Triviul feat. The Fiend - Widow']_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Secretariat - Borderline']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item[\"Little Chicago's Finest - My Own\"]_source1.wav (deflated 4%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Punkdisco - Oral Hygiene']_source1.wav (deflated 25%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Girls Under Glass - We Feel Alright']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['Sambasevam Shanmugam - Kaathaadi']_source2.wav (deflated 22%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Sunshine Garcia Band - For I Am The Moon']_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['The Easton Ellises (Baumi) - SDRNR']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['AM Contra - Heart Peripheral']_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/wavformer-libri2mix/1234/save/audio_results/item['PR - Happy Daze']_source1.wav (deflated 3%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /notebooks/file.zip /notebooks/results/wavformer-libri2mix/1234/save/audio_results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5211204,
     "sourceId": 8817844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
